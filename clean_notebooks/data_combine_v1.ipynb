{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/travisstowe/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (24,53) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "# load the starts data\n",
    "starts_df = pd.read_csv('../capstone_data/skillshare_2022_starts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the starts data.\n",
    "starts_df = starts_df[starts_df['plan_length'] == 12]\n",
    "starts_df = starts_df[starts_df['is_team'] == False]\n",
    "starts_df = starts_df[starts_df['is_scholarship'] == False]\n",
    "starts_df = starts_df[starts_df['is_direct_to_paid'] == False]\n",
    "starts_df = starts_df[starts_df['had_trial'] == True]\n",
    "starts_df = starts_df[starts_df['trial_length_offer'].isin(['One Week', 'One Month'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all of these columns have the chance to be valuable to us.\n",
    "valuable_cols = ['user_uid', 'is_active', 'create_time',\n",
    "       'first_payment_time', 'last_payment_time', 'next_billing_time',\n",
    "       'last_payment_attempt', 'last_failed_payment_attempt',\n",
    "       'user_cancellation_time', 'cancellation_time', 'refund_time', 'coupon_id',\n",
    "       'coupon_trial_length', 'payment_provider', 'payment_ux', 'is_paused',\n",
    "       'pause_time', 'is_refunded', 'is_resume', 'paid_through', 'is_lapsed', 'is_pending', 'is_cancelled',\n",
    "       'has_paid', 'is_paid', 'trial_end', 'category',\n",
    "       'num_payments', 'num_successful_payments',\n",
    "       'first_payment_currency_code', 'subscription_number',\n",
    "       'paid_subscription_number', 'eligible_subscription_number',\n",
    "       'is_p1_refunded', 'trial_extension_time',\n",
    "       'original_create_time', 'original_trial_end', 'extended_trial_end',\n",
    "       'was_trial_extended', 'is_trial_extension', 'is_split_trial',\n",
    "       'is_paid_reactivation', 'trial_length_days', 'trial_length_offer', 'sub_utm_source', 'sub_utm_campaign',\n",
    "       'sub_utm_medium', 'sub_utm_term', 'sub_utm_channel', 'referral_source',\n",
    "       'eligible_trial_number']\n",
    "\n",
    "starts_big_clean_df = starts_df[valuable_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the columns I bet will have some value to prediction.\n",
    "prediction_cols = ['user_uid', 'create_time', 'first_payment_time', 'last_payment_attempt',\n",
    "                   'last_failed_payment_attempt', 'user_cancellation_time', 'cancellation_time', \n",
    "                   'refund_time', 'coupon_id', 'coupon_trial_length', 'payment_provider', 'payment_ux', \n",
    "                   'is_refunded', 'has_paid', 'trial_end', 'first_payment_currency_code', 'original_trial_end', \n",
    "                   'extended_trial_end', 'was_trial_extended', 'is_trial_extension', 'is_split_trial', \n",
    "                   'trial_length_days', 'trial_length_offer', 'sub_utm_source', 'sub_utm_campaign', \n",
    "                   'sub_utm_medium', 'sub_utm_term', 'sub_utm_channel', 'referral_source', 'eligible_trial_number']\n",
    "\n",
    "starts_clean_df = starts_big_clean_df[prediction_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a day version of the trial start and end dates.\n",
    "starts_clean_df['trial_end_day'] = pd.to_datetime(starts_clean_df.original_trial_end).dt.date\n",
    "starts_clean_df['trial_start_day'] = pd.to_datetime(starts_clean_df.create_time).dt.date\n",
    "\n",
    "# for some reason user_uid is a float only on this table. Change it to an int.\n",
    "starts_clean_df['user_uid'] = starts_clean_df['user_uid'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a small df for merging onto the video views data.\n",
    "trial_ends = starts_clean_df[['user_uid', 'trial_start_day', 'trial_end_day']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ends = [x for x in range(63)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on file 0\n",
      "working on file 1\n",
      "working on file 2\n",
      "working on file 3\n",
      "working on file 4\n",
      "working on file 5\n",
      "working on file 6\n",
      "working on file 7\n",
      "working on file 8\n",
      "working on file 9\n",
      "working on file 10\n",
      "working on file 11\n",
      "working on file 12\n",
      "working on file 13\n",
      "working on file 14\n",
      "working on file 15\n",
      "working on file 16\n",
      "working on file 17\n",
      "working on file 18\n",
      "working on file 19\n",
      "working on file 20\n",
      "working on file 21\n",
      "working on file 22\n",
      "working on file 23\n",
      "working on file 24\n",
      "working on file 25\n",
      "working on file 26\n",
      "working on file 27\n",
      "working on file 28\n",
      "working on file 29\n",
      "working on file 30\n",
      "working on file 31\n",
      "working on file 32\n",
      "working on file 33\n",
      "working on file 34\n",
      "working on file 35\n",
      "working on file 36\n",
      "working on file 37\n",
      "working on file 38\n",
      "working on file 39\n",
      "working on file 40\n",
      "working on file 41\n",
      "working on file 42\n",
      "working on file 43\n",
      "working on file 44\n",
      "working on file 45\n",
      "working on file 46\n",
      "working on file 47\n",
      "working on file 48\n",
      "working on file 49\n",
      "working on file 50\n",
      "working on file 51\n",
      "working on file 52\n",
      "working on file 53\n",
      "working on file 54\n",
      "working on file 55\n",
      "working on file 56\n",
      "working on file 57\n",
      "working on file 58\n",
      "working on file 59\n",
      "working on file 60\n",
      "working on file 61\n",
      "working on file 62\n"
     ]
    }
   ],
   "source": [
    "full_user_df = pd.DataFrame()\n",
    "\n",
    "for x in file_ends:\n",
    "    print('working on file', x)\n",
    "    filename = '../capstone_data/skillshare_2022_vviews_'+str(x)+'.csv'\n",
    "    vviews_df = pd.read_csv(filename)\n",
    "    # print('file', x, 'has', len(vviews_df), 'rows')\n",
    "    vviews_df['view_date_dt'] = pd.to_datetime(vviews_df.view_date).dt.date\n",
    "    vviews_df = vviews_df.merge(trial_ends, how='left', left_on='uid', right_on='user_uid')\n",
    "    trial_vviews_df = vviews_df[vviews_df['view_date_dt'] < vviews_df['trial_end_day']]\n",
    "    trial_vviews_df['day_of_trial'] = (trial_vviews_df['view_date_dt'] - trial_vviews_df['trial_start_day']).dt.days + 1\n",
    "    trial_vviews_df = trial_vviews_df[trial_vviews_df['day_of_trial'] > 0]\n",
    "    ttv_df = trial_vviews_df.groupby(by=['uid', 'day_of_trial']).agg(minutes_watched=pd.NamedAgg(column='sum', aggfunc='sum')).reset_index()\n",
    "    vviews_pivot = ttv_df.pivot_table(\n",
    "        index=['uid'],\n",
    "        columns='day_of_trial',\n",
    "        values='minutes_watched').reset_index().rename_axis(None, axis=1).reset_index(drop=True).fillna(0.0)\n",
    "    #print('vviews_pivot for', x, 'has', len(vviews_pivot), 'rows')\n",
    "    full_user_df = full_user_df.append(vviews_pivot, ignore_index=True)\n",
    "    #print('full_user_df size:', len(full_user_df))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in full_user_df.columns:\n",
    "    if isinstance(x, int):\n",
    "        colname = 'day-'+str(x)\n",
    "        full_user_df.rename(columns={x: colname}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388016 388016\n"
     ]
    }
   ],
   "source": [
    "print(len(full_user_df), len(full_user_df.uid.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_user_df.to_csv('../capstone_data/skillshare_2022_all_views.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = starts_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['success'] = 0\n",
    "clean_df['success'][clean_df['first_payment_time'].notnull()] = 1\n",
    "clean_df['success'][clean_df['is_refunded']==1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['payment_provider_cat'] = clean_df['payment_provider'].astype('category')\n",
    "clean_df['payment_provider_cat_codes'] = clean_df['payment_provider_cat'].cat.codes\n",
    "\n",
    "clean_df['payment_ux_cat'] = clean_df['payment_ux'].astype('category')\n",
    "clean_df['payment_ux_cat_codes'] = clean_df['payment_ux_cat'].cat.codes\n",
    "\n",
    "clean_df['trial_length_offer_cat'] = clean_df['trial_length_offer'].astype('category')\n",
    "clean_df['trial_length_offer_cat_codes'] = clean_df['trial_length_offer_cat'].cat.codes\n",
    "\n",
    "clean_df['sub_utm_channel_cat'] = clean_df['sub_utm_channel'].astype('category')\n",
    "clean_df['sub_utm_channel_cat_codes'] = clean_df['sub_utm_channel_cat'].cat.codes\n",
    "\n",
    "clean_df['sub_utm_source_cat'] = clean_df['sub_utm_source'].astype('category')\n",
    "clean_df['sub_utm_source_cat_codes'] = clean_df['sub_utm_source_cat'].cat.codes\n",
    "\n",
    "clean_df['user_uid'] = clean_df['user_uid'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
