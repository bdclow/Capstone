{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process: \n",
    "# remove is_cancel = 1 and success = 1 (bad data)\n",
    "# One Hot Encode categorical columns\n",
    "# Add One Hot Buckets for 1 Day\n",
    "\n",
    "\n",
    "# Build Pipeline\n",
    "# split into 7 day v 30 day.\n",
    "# split 7 day into is_cancel v not_cancel\n",
    "# split 30 day into is_cancel v not_cancel\n",
    "# 1. 7 day + is_cancel = predict 0\n",
    "# 2. 30 day + is_cancel = predict 0\n",
    "# 3. 7 day ML\n",
    "# 4. 30 day ML\n",
    "# 5. Combine\n",
    "# 6. Get Scores.  Accuracy, Precision, Recall, F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data.\n",
    "combo_df = pd.read_csv('../../data/skillshare_combined.csv')\n",
    "combo_df = combo_df.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCEESSING\n",
    "# remove is_cancel = 1 and success = 1 (bad data)\n",
    "combo_df = combo_df[~((combo_df['success']==1) & (combo_df['is_cancel_during_trial']==1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encode categorical columns\n",
    "encoder = OneHotEncoder(drop='first', sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_df = pd.DataFrame(encoder.fit_transform(combo_df[['payment_provider_cat_codes']]))\n",
    "cols_names = ['pay_provider'+str(x) for x in list(encoder_df.columns)]\n",
    "encoder_df.columns = cols_names\n",
    "combo_df = combo_df.join(encoder_df)\n",
    "del combo_df['payment_provider_cat_codes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_df = pd.DataFrame(encoder.fit_transform(combo_df[['payment_ux_cat_codes']]))\n",
    "cols_names = ['pay_ux'+str(x) for x in list(encoder_df.columns)]\n",
    "encoder_df.columns = cols_names\n",
    "combo_df = combo_df.join(encoder_df)\n",
    "del combo_df['payment_ux_cat_codes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_df = pd.DataFrame(encoder.fit_transform(combo_df[['sub_utm_channel_cat_codes']]))\n",
    "# cols_names = ['channel'+str(x) for x in list(encoder_df.columns)]\n",
    "# encoder_df.columns = cols_names\n",
    "# combo_df = combo_df.join(encoder_df)\n",
    "# del combo_df['sub_utm_channel_cat_codes']\n",
    "### Too Many.  Get the top 5\n",
    "\n",
    "# 1. YTInfluencer\n",
    "combo_df['Is_YT'] = 0\n",
    "combo_df['Is_YT'][combo_df['sub_utm_channel_cat_codes'] == 17] = 1\n",
    "\n",
    "# 2. Paid Search (Brand)\n",
    "combo_df['Is_PSb'] = 0\n",
    "combo_df['Is_PSb'][combo_df['sub_utm_channel_cat_codes'] == 10] = 1\n",
    "\n",
    "# 3. Paid Search (Non-Brand)\n",
    "combo_df['Is_PSnb'] = 0\n",
    "combo_df['Is_PSnb'][combo_df['sub_utm_channel_cat_codes'] == 11] = 1\n",
    "\n",
    "# 4. Organic Search\n",
    "combo_df['Is_OS'] = 0\n",
    "combo_df['Is_OS'][combo_df['sub_utm_channel_cat_codes'] == 4] = 1\n",
    "\n",
    "# 5. Direct\n",
    "combo_df['Is_Direct'] = 0\n",
    "combo_df['Is_Direct'][combo_df['sub_utm_channel_cat_codes'] == 1] = 1\n",
    "\n",
    "# 6. Other\n",
    "above = [17, 10, 11, 4, 1]\n",
    "combo_df['Other_Channel'] = 0\n",
    "combo_df['Other_Channel'][~combo_df['sub_utm_channel_cat_codes'].isin(above)] = 1\n",
    "\n",
    "del combo_df['sub_utm_channel_cat_codes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'signup_country_name_cat_codes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'signup_country_name_cat_codes'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# encoder_df = pd.DataFrame(encoder.fit_transform(combo_df[['signup_country_name_cat_codes']]))\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# cols_names = ['country'+str(x) for x in list(encoder_df.columns)]\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# encoder_df.columns = cols_names\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m \n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# 1. Is_USA\u001b[39;00m\n\u001b[1;32m     17\u001b[0m combo_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIs_USA\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 18\u001b[0m combo_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIs_USA\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[43mcombo_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msignup_country_name_cat_codes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m214\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# 2. Is_UK\u001b[39;00m\n\u001b[1;32m     21\u001b[0m combo_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIs_UK\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'signup_country_name_cat_codes'"
     ]
    }
   ],
   "source": [
    "# encoder_df = pd.DataFrame(encoder.fit_transform(combo_df[['signup_country_name_cat_codes']]))\n",
    "# cols_names = ['country'+str(x) for x in list(encoder_df.columns)]\n",
    "# encoder_df.columns = cols_names\n",
    "# combo_df = combo_df.join(encoder_df)\n",
    "# del combo_df['signup_country_name_cat_codes']\n",
    "\n",
    "# encoder_df = pd.DataFrame(encoder.fit_transform(combo_df[['signup_geo_region_cat_codes']]))\n",
    "# cols_names = ['region'+str(x) for x in list(encoder_df.columns)]\n",
    "# encoder_df.columns = cols_names\n",
    "# combo_df = combo_df.join(encoder_df)\n",
    "# del combo_df['signup_geo_region_cat_codes']\n",
    "\n",
    "### TOO MANY.  Clean This.\n",
    "\n",
    "\n",
    "# 1. Is_USA\n",
    "combo_df['Is_USA'] = 0\n",
    "combo_df['Is_USA'][combo_df['signup_country_name_cat_codes'] == 214] = 1\n",
    "\n",
    "# 2. Is_UK\n",
    "combo_df['Is_UK'] = 0\n",
    "combo_df['Is_UK'][combo_df['signup_country_name_cat_codes'] == 213] = 1\n",
    "\n",
    "# 3. Is_WestEuro\n",
    "weuro = [185, 69, 75, 99, 161, 55, 142]\n",
    "combo_df['Is_WestEuro'] = 0\n",
    "combo_df['Is_WestEuro'][combo_df['signup_country_name_cat_codes'].isin(weuro)] = 1\n",
    "\n",
    "# 4. Is_CA\n",
    "combo_df['Is_CA'] = 0\n",
    "combo_df['Is_CA'][combo_df['signup_country_name_cat_codes'] == 35] = 1\n",
    "\n",
    "# 5. Is_IN\n",
    "combo_df['Is_IN'] = 0\n",
    "combo_df['Is_IN'][combo_df['signup_country_name_cat_codes'] == 92] = 1\n",
    "\n",
    "# 6. Other\n",
    "above = [214, 213, 185, 69, 75, 99, 161, 55, 142, 35, 92]\n",
    "combo_df['Other_Geo'] = 0\n",
    "combo_df['Other_Geo'][~combo_df['signup_country_name_cat_codes'].isin(above)] = 1\n",
    "\n",
    "del combo_df['signup_country_name_cat_codes']\n",
    "del combo_df['signup_geo_region_cat_codes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_df = pd.DataFrame(encoder.fit_transform(combo_df[['signup_platform_cat_codes']]))\n",
    "cols_names = ['platform'+str(x) for x in list(encoder_df.columns)]\n",
    "encoder_df.columns = cols_names\n",
    "combo_df = combo_df.join(encoder_df)\n",
    "del combo_df['signup_platform_cat_codes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NAs\n",
    "combo_df = combo_df.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete unneeded column\n",
    "del combo_df['sub_utm_source_cat_codes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a few cummulative minutes watched columns\n",
    "combo_df['d3_cumm'] =  combo_df['day-1'] + combo_df['day-2'] + combo_df['day-3']\n",
    "combo_df['d7_cumm'] =  combo_df['d3_cumm'] + combo_df['day-4'] + combo_df['day-5'] + combo_df['day-6'] + combo_df['day-7']\n",
    "\n",
    "# make a 30 day cummulative column\n",
    "combo_df['d30_cumm'] =  combo_df['d7_cumm']\n",
    "for x in range(23):\n",
    "    thiscol = 'day-'+str(x+8)\n",
    "    combo_df['d30_cumm'] =  combo_df['d30_cumm'] + combo_df[thiscol]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bucket the minutes watched based on the correlation visual.\n",
    "col = 'day-1'\n",
    "combo_df['d1_0'] = 0\n",
    "combo_df['d1_0'][combo_df[col] == 0.0] = 1\n",
    "\n",
    "combo_df['d1_1'] = 0\n",
    "combo_df['d1_1'][combo_df[col] > 0.0] = 1\n",
    "combo_df['d1_1'][combo_df[col] > 60.0] = 0\n",
    "\n",
    "combo_df['d1_5'] = 0\n",
    "combo_df['d1_5'][combo_df[col] >= 60.0] = 1\n",
    "combo_df['d1_5'][combo_df[col] > 300.0] = 0\n",
    "\n",
    "combo_df['d1_15'] = 0\n",
    "combo_df['d1_15'][combo_df[col] >= 300.0] = 1\n",
    "combo_df['d1_15'][combo_df[col] > 900.0] = 0\n",
    "\n",
    "combo_df['d1_30'] = 0\n",
    "combo_df['d1_30'][combo_df[col] >= 900.0] = 1\n",
    "combo_df['d1_30'][combo_df[col] > 1800.0] = 0\n",
    "\n",
    "combo_df['d1_60'] = 0\n",
    "combo_df['d1_60'][combo_df[col] >= 1800.0] = 1\n",
    "combo_df['d1_60'][combo_df[col] > 3600.0] = 0\n",
    "\n",
    "combo_df['d1_60'] = 0\n",
    "combo_df['d1_60'][combo_df[col] >= 3600.0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'd3_cumm'\n",
    "combo_df['d3_0'] = 0\n",
    "combo_df['d3_0'][combo_df[col] == 0.0] = 1\n",
    "\n",
    "combo_df['d3_1'] = 0\n",
    "combo_df['d3_1'][combo_df[col] > 0.0] = 1\n",
    "combo_df['d3_1'][combo_df[col] > 60.0] = 0\n",
    "\n",
    "combo_df['d3_5'] = 0\n",
    "combo_df['d3_5'][combo_df[col] >= 60.0] = 1\n",
    "combo_df['d3_5'][combo_df[col] > 300.0] = 0\n",
    "\n",
    "combo_df['d3_15'] = 0\n",
    "combo_df['d3_15'][combo_df[col] >= 300.0] = 1\n",
    "combo_df['d3_15'][combo_df[col] > 900.0] = 0\n",
    "\n",
    "combo_df['d3_30'] = 0\n",
    "combo_df['d3_30'][combo_df[col] >= 900.0] = 1\n",
    "combo_df['d3_30'][combo_df[col] > 1800.0] = 0\n",
    "\n",
    "combo_df['d3_60'] = 0\n",
    "combo_df['d3_60'][combo_df[col] >= 1800.0] = 1\n",
    "combo_df['d3_60'][combo_df[col] > 3600.0] = 0\n",
    "\n",
    "combo_df['d3_60'] = 0\n",
    "combo_df['d3_60'][combo_df[col] >= 3600.0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'd7_cumm'\n",
    "combo_df['d7_0'] = 0\n",
    "combo_df['d7_0'][combo_df[col] == 0.0] = 1\n",
    "\n",
    "combo_df['d7_1'] = 0\n",
    "combo_df['d7_1'][combo_df[col] > 0.0] = 1\n",
    "combo_df['d7_1'][combo_df[col] > 60.0] = 0\n",
    "\n",
    "combo_df['d7_5'] = 0\n",
    "combo_df['d7_5'][combo_df[col] >= 60.0] = 1\n",
    "combo_df['d7_5'][combo_df[col] > 300.0] = 0\n",
    "\n",
    "combo_df['d7_15'] = 0\n",
    "combo_df['d7_15'][combo_df[col] >= 300.0] = 1\n",
    "combo_df['d7_15'][combo_df[col] > 900.0] = 0\n",
    "\n",
    "combo_df['d7_30'] = 0\n",
    "combo_df['d7_30'][combo_df[col] >= 900.0] = 1\n",
    "combo_df['d7_30'][combo_df[col] > 1800.0] = 0\n",
    "\n",
    "combo_df['d7_60'] = 0\n",
    "combo_df['d7_60'][combo_df[col] >= 1800.0] = 1\n",
    "combo_df['d7_60'][combo_df[col] > 3600.0] = 0\n",
    "\n",
    "combo_df['d7_60'] = 0\n",
    "combo_df['d7_60'][combo_df[col] >= 3600.0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'd30_cumm'\n",
    "combo_df['d30_0'] = 0\n",
    "combo_df['d30_0'][combo_df[col] == 0.0] = 1\n",
    "\n",
    "combo_df['d30_1'] = 0\n",
    "combo_df['d30_1'][combo_df[col] > 0.0] = 1\n",
    "combo_df['d30_1'][combo_df[col] > 60.0] = 0\n",
    "\n",
    "combo_df['d30_5'] = 0\n",
    "combo_df['d30_5'][combo_df[col] >= 60.0] = 1\n",
    "combo_df['d30_5'][combo_df[col] > 300.0] = 0\n",
    "\n",
    "combo_df['d30_15'] = 0\n",
    "combo_df['d30_15'][combo_df[col] >= 300.0] = 1\n",
    "combo_df['d30_15'][combo_df[col] > 900.0] = 0\n",
    "\n",
    "combo_df['d30_30'] = 0\n",
    "combo_df['d30_30'][combo_df[col] >= 900.0] = 1\n",
    "combo_df['d30_30'][combo_df[col] > 1800.0] = 0\n",
    "\n",
    "combo_df['d30_60'] = 0\n",
    "combo_df['d30_60'][combo_df[col] >= 1800.0] = 1\n",
    "combo_df['d30_60'][combo_df[col] > 3600.0] = 0\n",
    "\n",
    "combo_df['d30_60'] = 0\n",
    "combo_df['d30_60'][combo_df[col] >= 3600.0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(31):\n",
    "    del combo_df['day-'+str(x+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into 7 day v 30 day.\n",
    "month_df = combo_df[combo_df['trial_length_offer_cat_codes'] == 0]\n",
    "week_df = combo_df[combo_df['trial_length_offer_cat_codes'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split 7 day into is_cancel v not_cancel\n",
    "week_df_cancel = week_df[week_df['is_cancel_during_trial']==1]\n",
    "week_df_elig = week_df[week_df['is_cancel_during_trial']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split 30 day into is_cancel v not_cancel\n",
    "month_df_cancel = month_df[month_df['is_cancel_during_trial']==1]\n",
    "month_df_elig = month_df[month_df['is_cancel_during_trial']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 7 day + is_cancel = predict 0\n",
    "y_w_c = week_df_cancel[['success']]\n",
    "y_w_c['predict'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 30 day + is_cancel = predict 0\n",
    "y_m_c = month_df_cancel[['success']]\n",
    "y_m_c['predict'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_df_elig.columns[6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 7 day ML\n",
    "X = week_df_elig[list(week_df_elig.columns)[6:]]\n",
    "y = week_df_elig['success']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a Decision Tree Classifier\n",
    "dtclf = DecisionTreeClassifier(max_depth=6).fit(X_train, y_train)\n",
    "y_pred = dtclf.predict(X_test)\n",
    "cm_dt = confusion_matrix(y_test, y_pred)\n",
    "print(cm_dt, dtclf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_w_e = pd.DataFrame({'success': y_test,  'predict' : y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 30 day ML\n",
    "y = month_df_elig['success']\n",
    "X = month_df_elig[list(month_df_elig.columns)[6:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a decision tree classifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "dtclf = DecisionTreeClassifier(max_depth=6).fit(X_train, y_train)\n",
    "y_pred = dtclf.predict(X_test)\n",
    "cm_dt = confusion_matrix(y_test, y_pred)\n",
    "print(cm_dt, dtclf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_m_e = pd.DataFrame({'success': y_test,  'predict' : y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Combine\n",
    "y_df = y_w_c.append(y_m_c)\n",
    "y_df = y_df.append(y_w_e)\n",
    "y_df = y_df.append(y_m_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: %.3f' % accuracy_score(y_df['success'], y_df['predict']))\n",
    "print('Precision: %.3f' % precision_score(y_df['success'], y_df['predict']))\n",
    "print('Recall: %.3f' % recall_score(y_df['success'], y_df['predict']))\n",
    "print('F1 Score: %.3f' % f1_score(y_df['success'], y_df['predict']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_overall = confusion_matrix(y_df['success'], y_df['predict'])\n",
    "cm_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_test), y_test.sum(), 1 - y_test.sum() / len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try KNeighbors?\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=8)\n",
    "neigh.fit(X_train, y_train)\n",
    "y_pred = neigh.predict(X_test)\n",
    "cm_dt = confusion_matrix(y_test, y_pred)\n",
    "print(cm_dt, neigh.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try Random Forest?\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(max_depth=6)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "cm_dt = confusion_matrix(y_test, y_pred)\n",
    "print(cm_dt, neigh.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
