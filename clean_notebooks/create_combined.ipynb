{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = pd.read_csv('~/capstone_data/skillshare_2022_starts_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a df of only the columms we want for prediction\n",
    "p_cols = ['user_uid', 'create_time', 'success', 'is_cancelled', 'payment_provider_cat_codes', 'payment_ux_cat_codes', \n",
    "          'trial_length_offer_cat_codes', 'sub_utm_channel_cat_codes', 'sub_utm_source_cat_codes', 'is_cancel_during_trial']\n",
    "mlready_df = clean_df[p_cols]\n",
    "\n",
    "# remove duplicates by keeping the most recent subscription for any user_uid.\n",
    "mlready_df.sort_values(by='create_time', inplace=True)\n",
    "mlready_df = mlready_df.drop_duplicates(subset=['user_uid'], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append the video views data onto the starts.\n",
    "# creation of video views data file found in data_combine_v1.py\n",
    "vviews_df = pd.read_csv('~/capstone_data/skillshare_2022_all_views.csv')\n",
    "\n",
    "# rename uid and remove unneeded columns.\n",
    "vviews_df.rename(columns={'uid':'user_uid'}, inplace=True)\n",
    "del vviews_df['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge vviews to starts data and fill in missing data with 0.\n",
    "combo_df = mlready_df.merge(vviews_df, how='left', on='user_uid')\n",
    "combo_df = combo_df.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### begin to translate non-video activity to merge.\n",
    "# make a df for merging the trial start and end.\n",
    "\n",
    "# when saved as csv, the date columns tend to revert to str, so to be sure:\n",
    "# make a day version of the trial start and end dates.\n",
    "clean_df['trial_end_day'] = pd.to_datetime(clean_df.original_trial_end).dt.date\n",
    "clean_df['trial_start_day'] = pd.to_datetime(clean_df.create_time).dt.date\n",
    "\n",
    "trial_ends = clean_df[['user_uid', 'trial_start_day', 'trial_end_day']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merge on Comments Data.\n",
    "# pull the comments data.\n",
    "comments_df = pd.read_csv('~/capstone_data/skillshare_2022_comments.csv')\n",
    "\n",
    "# change user_id column name for easy merge.\n",
    "comments_df.rename(columns={'user_id':'user_uid'}, inplace=True)\n",
    "\n",
    "# merge on the trial start and end.\n",
    "comments_df = comments_df.merge(trial_ends, how='left', on='user_uid')\n",
    "\n",
    "# round create_time to created_day.\n",
    "comments_df['create_day'] = pd.to_datetime(comments_df.create_time).dt.date\n",
    "\n",
    "# filter data to comments that happened during the user's trial\n",
    "comments_df = comments_df[comments_df['create_day'] > comments_df['trial_start_day']]\n",
    "comments_df = comments_df[comments_df['create_day'] < comments_df['trial_end_day']]\n",
    "\n",
    "# make a groupby that for each user_uid that includes num of comments and total comment score.\n",
    "comment_gb_df = comments_df.groupby(by=['user_uid']).agg(\n",
    "    comment_volume=pd.NamedAgg(column='id', aggfunc='count'), \n",
    "    comment_score=pd.NamedAgg(column='score', aggfunc='sum')).reset_index()\n",
    "\n",
    "# merge onto main dataframe.\n",
    "combo_df = combo_df.merge(comment_gb_df, how='left', on='user_uid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merge on Discussions Data.\n",
    "# Follow the same process as comments for discussions.\n",
    "discussions_df = pd.read_csv('~/capstone_data/skillshare_2022_discussions.csv')\n",
    "discussions_df.rename(columns={'user_id':'user_uid'}, inplace=True)\n",
    "discussions_df = discussions_df.merge(trial_ends, how='left', on='user_uid')\n",
    "discussions_df['create_day'] = pd.to_datetime(discussions_df.create_time).dt.date\n",
    "discussions_df = discussions_df[discussions_df['create_day'] > discussions_df['trial_start_day']]\n",
    "discussions_df = discussions_df[discussions_df['create_day'] < discussions_df['trial_end_day']]\n",
    "discussions_gb_df = discussions_df.groupby(by=['user_uid']).agg(\n",
    "    discussion_volume=pd.NamedAgg(column='id', aggfunc='count'), \n",
    "    discussion_score=pd.NamedAgg(column='score', aggfunc='sum')).reset_index()\n",
    "combo_df = combo_df.merge(discussions_gb_df, how='left', on='user_uid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merge on Follows Data.\n",
    "# Follow the same process as comments for follows.\n",
    "follows_df = pd.read_csv('~/capstone_data/skillshare_2022_follows.csv')\n",
    "follows_df.rename(columns={'follower_uid':'user_uid'}, inplace=True)\n",
    "follows_df = follows_df.merge(trial_ends, how='left', on='user_uid')\n",
    "follows_df['follow_day'] = pd.to_datetime(follows_df.follow_time).dt.date\n",
    "follows_df = follows_df[follows_df['follow_day'] > follows_df['trial_start_day']]\n",
    "follows_df = follows_df[follows_df['follow_day'] < follows_df['trial_end_day']]\n",
    "\n",
    "# make a groupby by user_uid that counts the number of follows.\n",
    "follows_gb_df = follows_df.groupby(by=['user_uid']).agg(\n",
    "    follow_volume=pd.NamedAgg(column='target_uid', aggfunc='count')).reset_index()\n",
    "combo_df = combo_df.merge(follows_gb_df, how='left', on='user_uid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merge on Projects Data.\n",
    "# Follow the same process as comments for follows.\n",
    "projects_df = pd.read_csv('~/capstone_data/skillshare_2022_projects.csv')\n",
    "projects_df.rename(columns={'uid':'user_uid'}, inplace=True)\n",
    "projects_df = projects_df.merge(trial_ends, how='left', on='user_uid')\n",
    "projects_df['create_day'] = pd.to_datetime(projects_df.create_time).dt.date\n",
    "projects_df = projects_df[projects_df['create_day'] > projects_df['trial_start_day']]\n",
    "projects_df = projects_df[projects_df['create_day'] < projects_df['trial_end_day']]\n",
    "projects_gb_df = projects_df.groupby(by=['user_uid']).agg(\n",
    "    projects_volume=pd.NamedAgg(column='id', aggfunc='count'), \n",
    "    projects_score=pd.NamedAgg(column='num_up', aggfunc='sum')).reset_index()\n",
    "combo_df = combo_df.merge(projects_gb_df, how='left', on='user_uid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merge on Reviews Data.\n",
    "# Follow the same process as comments for follows.\n",
    "reviews_df = pd.read_csv('~/capstone_data/skillshare_2022_reviews.csv')\n",
    "reviews_df.rename(columns={'uid':'user_uid'}, inplace=True)\n",
    "reviews_df = reviews_df.merge(trial_ends, how='left', on='user_uid')\n",
    "reviews_df['create_day'] = pd.to_datetime(reviews_df.create_time).dt.date\n",
    "reviews_df = reviews_df[reviews_df['create_day'] > reviews_df['trial_start_day']]\n",
    "reviews_df = reviews_df[reviews_df['create_day'] < reviews_df['trial_end_day']]\n",
    "\n",
    "# make a groupby for each user and their volume of reviews and avg review score.\n",
    "reviews_gb_df = reviews_df.groupby(by=['user_uid']).agg(\n",
    "    review_volume=pd.NamedAgg(column='review_id', aggfunc='count'), \n",
    "    rating_avg=pd.NamedAgg(column='rating', aggfunc='mean')).reset_index()\n",
    "combo_df = combo_df.merge(reviews_gb_df, how='left', on='user_uid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### begin to merge on subscriber location meta data\n",
    "subs_meta_df = pd.read_csv('~/capstone_data/skillshare_subs_meta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_df = combo_df.merge(subs_meta_df, how='left', on='user_uid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_df['signup_country_name_cat'] = combo_df['signup_country_name'].astype('category')\n",
    "combo_df['signup_country_name_cat_codes'] = combo_df['signup_country_name_cat'].cat.codes\n",
    "\n",
    "combo_df['signup_geo_region_cat'] = combo_df['signup_geo_region'].astype('category')\n",
    "combo_df['signup_geo_region_cat_codes'] = combo_df['signup_geo_region_cat'].cat.codes\n",
    "\n",
    "combo_df['signup_platform_cat'] = combo_df['signup_platform'].astype('category')\n",
    "combo_df['signup_platform_cat_codes'] = combo_df['signup_platform_cat'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "payment_provider_lookup_df = combo_df.groupby(\n",
    "    by=['signup_country_name', 'signup_country_name_cat_codes']).agg(\n",
    "        volume=pd.NamedAgg(column='user_uid', aggfunc='count')).reset_index()\n",
    "payment_provider_lookup_df.to_csv('~/capstone_data/lookup_country_name.csv', index=False)\n",
    "\n",
    "payment_ux_df = combo_df.groupby(\n",
    "    by=['signup_geo_region', 'signup_geo_region_cat_codes']).agg(\n",
    "        volume=pd.NamedAgg(column='user_uid', aggfunc='count')).reset_index()\n",
    "payment_ux_df.to_csv('~/capstone_data/lookup_geo_region.csv', index=False)\n",
    "\n",
    "trial_length_df = combo_df.groupby(\n",
    "    by=['signup_platform', 'signup_platform_cat_codes']).agg(\n",
    "        volume=pd.NamedAgg(column='user_uid', aggfunc='count')).reset_index()\n",
    "trial_length_df.to_csv('~/capstone_data/lookup_platform.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "del combo_df['signup_country_name']\n",
    "del combo_df['signup_geo_region']\n",
    "del combo_df['signup_platform']\n",
    "del combo_df['signup_country_name_cat']\n",
    "del combo_df['signup_geo_region_cat']\n",
    "del combo_df['signup_platform_cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export data\n",
    "combo_df.to_csv('~/capstone_data/skillshare_combined.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
