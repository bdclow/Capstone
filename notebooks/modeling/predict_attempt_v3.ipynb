{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process: \n",
    "# remove is_cancel = 1 and success = 1 (bad data)\n",
    "# One Hot Encode categorical columns\n",
    "# Add One Hot Buckets for 1 Day\n",
    "\n",
    "\n",
    "# Build Pipeline\n",
    "# split into 7 day v 30 day.\n",
    "# split 7 day into is_cancel v not_cancel\n",
    "# split 30 day into is_cancel v not_cancel\n",
    "# 1. 7 day + is_cancel = predict 0\n",
    "# 2. 30 day + is_cancel = predict 0\n",
    "# 3. 7 day ML\n",
    "# 4. 30 day ML\n",
    "# 5. Combine\n",
    "# 6. Get Scores.  Accuracy, Precision, Recall, F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score, auc, roc_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data.\n",
    "combo_df = pd.read_csv('../../data/skillshare_combined.csv')\n",
    "combo_df = combo_df.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCEESSING\n",
    "# remove is_cancel = 1 and success = 1 (bad data)\n",
    "combo_df = combo_df[~((combo_df['success']==1) & (combo_df['is_cancel_during_trial']==1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encode categorical columns\n",
    "encoder = OneHotEncoder(drop='first', sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_df = pd.DataFrame(encoder.fit_transform(combo_df[['payment_provider_cat_codes']]))\n",
    "cols_names = ['pay_provider'+str(x) for x in list(encoder_df.columns)]\n",
    "encoder_df.columns = cols_names\n",
    "combo_df = combo_df.join(encoder_df)\n",
    "del combo_df['payment_provider_cat_codes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_df = pd.DataFrame(encoder.fit_transform(combo_df[['payment_ux_cat_codes']]))\n",
    "cols_names = ['pay_ux'+str(x) for x in list(encoder_df.columns)]\n",
    "encoder_df.columns = cols_names\n",
    "combo_df = combo_df.join(encoder_df)\n",
    "del combo_df['payment_ux_cat_codes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_df = pd.DataFrame(encoder.fit_transform(combo_df[['sub_utm_channel_cat_codes']]))\n",
    "# cols_names = ['channel'+str(x) for x in list(encoder_df.columns)]\n",
    "# encoder_df.columns = cols_names\n",
    "# combo_df = combo_df.join(encoder_df)\n",
    "# del combo_df['sub_utm_channel_cat_codes']\n",
    "### Too Many.  Get the top 5\n",
    "\n",
    "# 1. YTInfluencer\n",
    "combo_df['Is_YT'] = 0\n",
    "combo_df['Is_YT'][combo_df['sub_utm_channel_cat_codes'] == 17] = 1\n",
    "\n",
    "# 2. Paid Search (Brand)\n",
    "combo_df['Is_PSb'] = 0\n",
    "combo_df['Is_PSb'][combo_df['sub_utm_channel_cat_codes'] == 10] = 1\n",
    "\n",
    "# 3. Paid Search (Non-Brand)\n",
    "combo_df['Is_PSnb'] = 0\n",
    "combo_df['Is_PSnb'][combo_df['sub_utm_channel_cat_codes'] == 11] = 1\n",
    "\n",
    "# 4. Organic Search\n",
    "combo_df['Is_OS'] = 0\n",
    "combo_df['Is_OS'][combo_df['sub_utm_channel_cat_codes'] == 4] = 1\n",
    "\n",
    "# 5. Direct\n",
    "combo_df['Is_Direct'] = 0\n",
    "combo_df['Is_Direct'][combo_df['sub_utm_channel_cat_codes'] == 1] = 1\n",
    "\n",
    "# 6. Other\n",
    "above = [17, 10, 11, 4, 1]\n",
    "combo_df['Other_Channel'] = 0\n",
    "combo_df['Other_Channel'][~combo_df['sub_utm_channel_cat_codes'].isin(above)] = 1\n",
    "\n",
    "del combo_df['sub_utm_channel_cat_codes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_df = pd.DataFrame(encoder.fit_transform(combo_df[['signup_country_name_cat_codes']]))\n",
    "# cols_names = ['country'+str(x) for x in list(encoder_df.columns)]\n",
    "# encoder_df.columns = cols_names\n",
    "# combo_df = combo_df.join(encoder_df)\n",
    "# del combo_df['signup_country_name_cat_codes']\n",
    "\n",
    "# encoder_df = pd.DataFrame(encoder.fit_transform(combo_df[['signup_geo_region_cat_codes']]))\n",
    "# cols_names = ['region'+str(x) for x in list(encoder_df.columns)]\n",
    "# encoder_df.columns = cols_names\n",
    "# combo_df = combo_df.join(encoder_df)\n",
    "# del combo_df['signup_geo_region_cat_codes']\n",
    "\n",
    "### TOO MANY.  Clean This.\n",
    "\n",
    "\n",
    "# 1. Is_USA\n",
    "combo_df['Is_USA'] = 0\n",
    "combo_df['Is_USA'][combo_df['signup_country_name_cat_codes'] == 214] = 1\n",
    "\n",
    "# 2. Is_UK\n",
    "combo_df['Is_UK'] = 0\n",
    "combo_df['Is_UK'][combo_df['signup_country_name_cat_codes'] == 213] = 1\n",
    "\n",
    "# 3. Is_WestEuro\n",
    "weuro = [185, 69, 75, 99, 161, 55, 142]\n",
    "combo_df['Is_WestEuro'] = 0\n",
    "combo_df['Is_WestEuro'][combo_df['signup_country_name_cat_codes'].isin(weuro)] = 1\n",
    "\n",
    "# 4. Is_CA\n",
    "combo_df['Is_CA'] = 0\n",
    "combo_df['Is_CA'][combo_df['signup_country_name_cat_codes'] == 35] = 1\n",
    "\n",
    "# 5. Is_IN\n",
    "combo_df['Is_IN'] = 0\n",
    "combo_df['Is_IN'][combo_df['signup_country_name_cat_codes'] == 92] = 1\n",
    "\n",
    "# 6. Other\n",
    "above = [214, 213, 185, 69, 75, 99, 161, 55, 142, 35, 92]\n",
    "combo_df['Other_Geo'] = 0\n",
    "combo_df['Other_Geo'][~combo_df['signup_country_name_cat_codes'].isin(above)] = 1\n",
    "\n",
    "del combo_df['signup_country_name_cat_codes']\n",
    "del combo_df['signup_geo_region_cat_codes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_df = pd.DataFrame(encoder.fit_transform(combo_df[['signup_platform_cat_codes']]))\n",
    "cols_names = ['platform'+str(x) for x in list(encoder_df.columns)]\n",
    "encoder_df.columns = cols_names\n",
    "combo_df = combo_df.join(encoder_df)\n",
    "del combo_df['signup_platform_cat_codes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NAs\n",
    "combo_df = combo_df.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete unneeded column\n",
    "del combo_df['sub_utm_source_cat_codes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a few cummulative minutes watched columns\n",
    "combo_df['d3_cumm'] =  combo_df['day-1'] + combo_df['day-2'] + combo_df['day-3']\n",
    "combo_df['d7_cumm'] =  combo_df['d3_cumm'] + combo_df['day-4'] + combo_df['day-5'] + combo_df['day-6'] + combo_df['day-7']\n",
    "\n",
    "# make a 30 day cummulative column\n",
    "combo_df['d30_cumm'] =  combo_df['d7_cumm']\n",
    "for x in range(23):\n",
    "    thiscol = 'day-'+str(x+8)\n",
    "    combo_df['d30_cumm'] =  combo_df['d30_cumm'] + combo_df[thiscol]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bucket the minutes watched based on the correlation visual.\n",
    "col = 'day-1'\n",
    "combo_df['d1_0'] = 0\n",
    "combo_df['d1_0'][combo_df[col] == 0.0] = 1\n",
    "\n",
    "combo_df['d1_1'] = 0\n",
    "combo_df['d1_1'][combo_df[col] > 0.0] = 1\n",
    "combo_df['d1_1'][combo_df[col] > 60.0] = 0\n",
    "\n",
    "combo_df['d1_5'] = 0\n",
    "combo_df['d1_5'][combo_df[col] >= 60.0] = 1\n",
    "combo_df['d1_5'][combo_df[col] > 300.0] = 0\n",
    "\n",
    "combo_df['d1_15'] = 0\n",
    "combo_df['d1_15'][combo_df[col] >= 300.0] = 1\n",
    "combo_df['d1_15'][combo_df[col] > 900.0] = 0\n",
    "\n",
    "combo_df['d1_30'] = 0\n",
    "combo_df['d1_30'][combo_df[col] >= 900.0] = 1\n",
    "combo_df['d1_30'][combo_df[col] > 1800.0] = 0\n",
    "\n",
    "combo_df['d1_60'] = 0\n",
    "combo_df['d1_60'][combo_df[col] >= 1800.0] = 1\n",
    "combo_df['d1_60'][combo_df[col] > 3600.0] = 0\n",
    "\n",
    "combo_df['d1_60'] = 0\n",
    "combo_df['d1_60'][combo_df[col] >= 3600.0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'd3_cumm'\n",
    "combo_df['d3_0'] = 0\n",
    "combo_df['d3_0'][combo_df[col] == 0.0] = 1\n",
    "\n",
    "combo_df['d3_1'] = 0\n",
    "combo_df['d3_1'][combo_df[col] > 0.0] = 1\n",
    "combo_df['d3_1'][combo_df[col] > 60.0] = 0\n",
    "\n",
    "combo_df['d3_5'] = 0\n",
    "combo_df['d3_5'][combo_df[col] >= 60.0] = 1\n",
    "combo_df['d3_5'][combo_df[col] > 300.0] = 0\n",
    "\n",
    "combo_df['d3_15'] = 0\n",
    "combo_df['d3_15'][combo_df[col] >= 300.0] = 1\n",
    "combo_df['d3_15'][combo_df[col] > 900.0] = 0\n",
    "\n",
    "combo_df['d3_30'] = 0\n",
    "combo_df['d3_30'][combo_df[col] >= 900.0] = 1\n",
    "combo_df['d3_30'][combo_df[col] > 1800.0] = 0\n",
    "\n",
    "combo_df['d3_60'] = 0\n",
    "combo_df['d3_60'][combo_df[col] >= 1800.0] = 1\n",
    "combo_df['d3_60'][combo_df[col] > 3600.0] = 0\n",
    "\n",
    "combo_df['d3_60'] = 0\n",
    "combo_df['d3_60'][combo_df[col] >= 3600.0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'd7_cumm'\n",
    "combo_df['d7_0'] = 0\n",
    "combo_df['d7_0'][combo_df[col] == 0.0] = 1\n",
    "\n",
    "combo_df['d7_1'] = 0\n",
    "combo_df['d7_1'][combo_df[col] > 0.0] = 1\n",
    "combo_df['d7_1'][combo_df[col] > 60.0] = 0\n",
    "\n",
    "combo_df['d7_5'] = 0\n",
    "combo_df['d7_5'][combo_df[col] >= 60.0] = 1\n",
    "combo_df['d7_5'][combo_df[col] > 300.0] = 0\n",
    "\n",
    "combo_df['d7_15'] = 0\n",
    "combo_df['d7_15'][combo_df[col] >= 300.0] = 1\n",
    "combo_df['d7_15'][combo_df[col] > 900.0] = 0\n",
    "\n",
    "combo_df['d7_30'] = 0\n",
    "combo_df['d7_30'][combo_df[col] >= 900.0] = 1\n",
    "combo_df['d7_30'][combo_df[col] > 1800.0] = 0\n",
    "\n",
    "combo_df['d7_60'] = 0\n",
    "combo_df['d7_60'][combo_df[col] >= 1800.0] = 1\n",
    "combo_df['d7_60'][combo_df[col] > 3600.0] = 0\n",
    "\n",
    "combo_df['d7_60'] = 0\n",
    "combo_df['d7_60'][combo_df[col] >= 3600.0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'd30_cumm'\n",
    "combo_df['d30_0'] = 0\n",
    "combo_df['d30_0'][combo_df[col] == 0.0] = 1\n",
    "\n",
    "combo_df['d30_1'] = 0\n",
    "combo_df['d30_1'][combo_df[col] > 0.0] = 1\n",
    "combo_df['d30_1'][combo_df[col] > 60.0] = 0\n",
    "\n",
    "combo_df['d30_5'] = 0\n",
    "combo_df['d30_5'][combo_df[col] >= 60.0] = 1\n",
    "combo_df['d30_5'][combo_df[col] > 300.0] = 0\n",
    "\n",
    "combo_df['d30_15'] = 0\n",
    "combo_df['d30_15'][combo_df[col] >= 300.0] = 1\n",
    "combo_df['d30_15'][combo_df[col] > 900.0] = 0\n",
    "\n",
    "combo_df['d30_30'] = 0\n",
    "combo_df['d30_30'][combo_df[col] >= 900.0] = 1\n",
    "combo_df['d30_30'][combo_df[col] > 1800.0] = 0\n",
    "\n",
    "combo_df['d30_60'] = 0\n",
    "combo_df['d30_60'][combo_df[col] >= 1800.0] = 1\n",
    "combo_df['d30_60'][combo_df[col] > 3600.0] = 0\n",
    "\n",
    "combo_df['d30_60'] = 0\n",
    "combo_df['d30_60'][combo_df[col] >= 3600.0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(31):\n",
    "    del combo_df['day-'+str(x+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_uid', 'create_time', 'success', 'is_cancelled',\n",
       "       'trial_length_offer_cat_codes', 'is_cancel_during_trial',\n",
       "       'comment_volume', 'comment_score', 'discussion_volume',\n",
       "       'discussion_score', 'follow_volume', 'projects_volume',\n",
       "       'projects_score', 'review_volume', 'rating_avg', 'pay_provider0',\n",
       "       'pay_provider1', 'pay_provider2', 'pay_provider3', 'pay_ux0', 'pay_ux1',\n",
       "       'pay_ux2', 'pay_ux3', 'pay_ux4', 'pay_ux5', 'pay_ux6', 'pay_ux7',\n",
       "       'pay_ux8', 'pay_ux9', 'Is_YT', 'Is_PSb', 'Is_PSnb', 'Is_OS',\n",
       "       'Is_Direct', 'Other_Channel', 'Is_USA', 'Is_UK', 'Is_WestEuro', 'Is_CA',\n",
       "       'Is_IN', 'Other_Geo', 'platform0', 'platform1', 'platform2', 'd3_cumm',\n",
       "       'd7_cumm', 'd30_cumm', 'd1_0', 'd1_1', 'd1_5', 'd1_15', 'd1_30',\n",
       "       'd1_60', 'd3_0', 'd3_1', 'd3_5', 'd3_15', 'd3_30', 'd3_60', 'd7_0',\n",
       "       'd7_1', 'd7_5', 'd7_15', 'd7_30', 'd7_60', 'd30_0', 'd30_1', 'd30_5',\n",
       "       'd30_15', 'd30_30', 'd30_60'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combo_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into 7 day v 30 day.\n",
    "month_df = combo_df[combo_df['trial_length_offer_cat_codes'] == 0]\n",
    "week_df = combo_df[combo_df['trial_length_offer_cat_codes'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split 7 day into is_cancel v not_cancel\n",
    "week_df_cancel = week_df[week_df['is_cancel_during_trial']==1]\n",
    "week_df_elig = week_df[week_df['is_cancel_during_trial']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split 30 day into is_cancel v not_cancel\n",
    "month_df_cancel = month_df[month_df['is_cancel_during_trial']==1]\n",
    "month_df_elig = month_df[month_df['is_cancel_during_trial']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 7 day + is_cancel = predict 0\n",
    "y_w_c = week_df_cancel[['success']]\n",
    "y_w_c['predict'] = 0\n",
    "y_w_c['probs'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 30 day + is_cancel = predict 0\n",
    "y_m_c = month_df_cancel[['success']]\n",
    "y_m_c['predict'] = 0\n",
    "y_m_c['probs'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['comment_volume', 'comment_score', 'discussion_volume',\n",
       "       'discussion_score', 'follow_volume', 'projects_volume',\n",
       "       'projects_score', 'review_volume', 'rating_avg', 'pay_provider0',\n",
       "       'pay_provider1', 'pay_provider2', 'pay_provider3', 'pay_ux0', 'pay_ux1',\n",
       "       'pay_ux2', 'pay_ux3', 'pay_ux4', 'pay_ux5', 'pay_ux6', 'pay_ux7',\n",
       "       'pay_ux8', 'pay_ux9', 'Is_YT', 'Is_PSb', 'Is_PSnb', 'Is_OS',\n",
       "       'Is_Direct', 'Other_Channel', 'Is_USA', 'Is_UK', 'Is_WestEuro', 'Is_CA',\n",
       "       'Is_IN', 'Other_Geo', 'platform0', 'platform1', 'platform2', 'd3_cumm',\n",
       "       'd7_cumm', 'd30_cumm', 'd1_0', 'd1_1', 'd1_5', 'd1_15', 'd1_30',\n",
       "       'd1_60', 'd3_0', 'd3_1', 'd3_5', 'd3_15', 'd3_30', 'd3_60', 'd7_0',\n",
       "       'd7_1', 'd7_5', 'd7_15', 'd7_30', 'd7_60'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "week_df_elig.columns[6:65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 7 day ML\n",
    "X_week = week_df_elig[list(week_df_elig.columns)[6:65]]\n",
    "y_week = week_df_elig['success']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5282 2505]\n",
      " [3100 3354]] 0.6064180886173723\n"
     ]
    }
   ],
   "source": [
    "# run a Decision Tree Classifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_week, y_week, test_size=0.2)\n",
    "rf_week = RandomForestClassifier(max_depth=7).fit(X_train, y_train)\n",
    "y_pred = rf_week.predict(X_test)\n",
    "cm_dt = confusion_matrix(y_test, y_pred)\n",
    "print(cm_dt, rf_week.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6358795890698302\n"
     ]
    }
   ],
   "source": [
    "y_probs = rf_week.predict_proba(X_test)\n",
    "y_probs_p1 = [x[1] for x in y_probs]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_probs_p1)\n",
    "week_auc = auc(fpr, tpr)\n",
    "print(week_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_w_e = pd.DataFrame({'success': y_test,  'predict' : y_pred, 'probs': y_probs_p1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 30 day ML\n",
    "y_month = month_df_elig['success']\n",
    "X_month = month_df_elig[list(month_df_elig.columns)[6:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24763  1073]\n",
      " [13943  1827]] 0.6390905157909916\n"
     ]
    }
   ],
   "source": [
    "# run a decision tree classifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_month, y_month, test_size=0.2)\n",
    "rf_month = RandomForestClassifier(max_depth=7).fit(X_train, y_train)\n",
    "y_pred = rf_month.predict(X_test)\n",
    "cm_dt = confusion_matrix(y_test, y_pred)\n",
    "print(cm_dt, rf_month.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6450499003862518\n"
     ]
    }
   ],
   "source": [
    "y_probs = rf_month.predict_proba(X_test)\n",
    "y_probs_p1 = [x[1] for x in y_probs]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_probs_p1)\n",
    "week_auc = auc(fpr, tpr)\n",
    "print(week_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_m_e = pd.DataFrame({'success': y_test,  'predict' : y_pred, 'probs': y_probs_p1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Combine\n",
    "y_df = y_w_c.append(y_m_c)\n",
    "y_df = y_df.append(y_w_e)\n",
    "y_df = y_df.append(y_m_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.918\n",
      "Precision: 0.592\n",
      "Recall: 0.233\n",
      "F1 Score: 0.334\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: %.3f' % accuracy_score(y_df['success'], y_df['predict']))\n",
    "print('Precision: %.3f' % precision_score(y_df['success'], y_df['predict']))\n",
    "print('Recall: %.3f' % recall_score(y_df['success'], y_df['predict']))\n",
    "print('F1 Score: %.3f' % f1_score(y_df['success'], y_df['predict']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[224176,   3578],\n",
       "       [ 17043,   5181]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_overall = confusion_matrix(y_df['success'], y_df['predict'])\n",
    "cm_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9478407922142171\n"
     ]
    }
   ],
   "source": [
    "y_test = y_df['success']\n",
    "y_probs = y_df['probs']\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
    "week_auc = auc(fpr, tpr)\n",
    "print(week_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>success</th>\n",
       "      <th>predict</th>\n",
       "      <th>probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    success  predict  probs\n",
       "14        0        0    0.0\n",
       "19        0        0    0.0\n",
       "39        0        0    0.0\n",
       "45        0        0    0.0\n",
       "54        0        0    0.0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
